#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
G2Retro-P è®¾è®¡æ–¹æ¡ˆå®Œå…¨å¯¹é½å®ç°
ä¸¥æ ¼æŒ‰ç…§"åŸºäºå¤šä»»åŠ¡é¢„è®­ç»ƒçš„åŠæ¨¡æ¿é€†åˆæˆæ¨¡å‹è®¾è®¡æ–¹æ¡ˆ"å®ç°

æ ¸å¿ƒåˆ›æ–°ç‚¹éªŒè¯ï¼š
1. å…±äº«ç¼–ç å™¨ï¼šå®Œå…¨æ²¿ç”¨G2Retroçš„æ ¸å¿ƒç»„ä»¶GMPN
2. åŸºç¡€ä»»åŠ¡å¤´ï¼šç›´æ¥é‡‡ç”¨G2Retroçš„ååº”ä¸­å¿ƒè¯†åˆ«æ¨¡å—  
3. åˆ†å­æ¢å¤å¤´ï¼šé‡‡ç”¨MolCLRçš„ä¸‰ç§å›¾å¢å¼ºç­–ç•¥
4. äº§ç‰©-åˆæˆå­å¯¹æ¯”å¤´ï¼šæ ¸å¿ƒåˆ›æ–°ï¼Œå®Œç¾ä»»åŠ¡å¯¹é½
5. æ•°æ®æµç¨‹ï¼šGp â†’ h_product, Gp_aug â†’ h_augmented, Gs â†’ h_synthons
6. æŸå¤±æƒé‡ï¼šL_total = L_base + L_recovery + 0.1 Ã— L_contrastive
"""

import sys
import os
import pickle
import copy
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
from collections import defaultdict
import time
import random
import rdkit.Chem as Chem
import torch.nn.functional as F

# å¯¼å…¥G2Retroæ ¸å¿ƒæ¨¡å—
from mol_tree import MolTree
from mol_enc import MolEncoder
from molcenter import MolCenter, make_cuda
from chemutils import get_mol
from vocab import Vocab, common_atom_vocab
from nnutils import create_pad_tensor, index_select_ND
from config import device

# å¯¼å…¥é¢„è®­ç»ƒä»»åŠ¡å¤´
from molecule_recovery_head import MoleculeRecoveryHead
from product_synthon_contrastive_head import ProductSynthonContrastiveHead

# å¯¼å…¥æ•°æ®é›†ç›¸å…³ç»„ä»¶
from g2retro_p_dataset import G2RetroPDesignAlignedDataset, g2retro_design_aligned_collate_fn


class G2RetroPDesignAlignedModel(nn.Module):
    """
    å®Œå…¨ç¬¦åˆè®¾è®¡æ–¹æ¡ˆçš„G2Retro-Pæ¨¡å‹
    
    è®¾è®¡æ–¹æ¡ˆæ ¸å¿ƒæ¶æ„ï¼š
    - é¢„è®­ç»ƒé˜¶æ®µ: æ­¤é˜¶æ®µæ˜¯æ¨¡å‹å­¦ä¹ çš„æ ¸å¿ƒã€‚æ¨¡å‹ç”±ä¸€ä¸ªå…±äº«ç¼–ç å™¨å’Œä¸‰ä¸ªå¹¶è¡Œçš„ä»»åŠ¡å¤´ç»„æˆ
    - å…±äº«ç¼–ç å™¨: å®Œå…¨æ²¿ç”¨G2Retroçš„æ ¸å¿ƒç»„ä»¶GMPNï¼ˆå›¾æ¶ˆæ¯ä¼ é€’ç½‘ç»œï¼‰
    - å¹¶è¡Œä»»åŠ¡å¤´:
      1. åŸºç¡€ä»»åŠ¡å¤´: ç›´æ¥é‡‡ç”¨G2Retroçš„ååº”ä¸­å¿ƒè¯†åˆ«æ¨¡å—
      2. åˆ†å­æ¢å¤å¤´: é‡‡ç”¨MolCLRçš„ä¸‰ç§å›¾å¢å¼ºç­–ç•¥
      3. äº§ç‰©-åˆæˆå­å¯¹æ¯”å¤´ï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼‰: ç›´æ¥åˆ©ç”¨äº§ç‰©ä¸åˆæˆå­é—´çš„è‡ªç„¶å·®å¼‚è¿›è¡Œå¯¹æ¯”å­¦ä¹ 
    """
    def __init__(self, vocab, avocab, args):
        super(G2RetroPDesignAlignedModel, self).__init__()
        
        self.vocab = vocab
        self.avocab = avocab
        self.hidden_size = args.hidden_size
        self.latent_size = args.latent_size
        
        # æŒ‰ç…§è®¾è®¡æ–¹æ¡ˆï¼šå…±äº«ç¼–ç å™¨å®Œå…¨æ²¿ç”¨G2Retroçš„æ ¸å¿ƒç»„ä»¶GMPN
        print("åˆå§‹åŒ–å…±äº«ç¼–ç å™¨ï¼ˆGMPNï¼‰...")
        self.mol_center = MolCenter(vocab, avocab, args)
        # æå–å…±äº«çš„GMPNç¼–ç å™¨
        self.shared_encoder = self.mol_center.encoder  # è¿™å°±æ˜¯GMPN
        
        # æŒ‰ç…§è®¾è®¡æ–¹æ¡ˆï¼šä¸‰ä¸ªå¹¶è¡Œä»»åŠ¡å¤´
        print("åˆå§‹åŒ–ä¸‰ä¸ªå¹¶è¡Œä»»åŠ¡å¤´...")
        
        # 1. åŸºç¡€ä»»åŠ¡å¤´ï¼šç›´æ¥é‡‡ç”¨G2Retroçš„ååº”ä¸­å¿ƒè¯†åˆ«æ¨¡å—
        print("  - åŸºç¡€ä»»åŠ¡å¤´ï¼šG2Retroååº”ä¸­å¿ƒè¯†åˆ«æ¨¡å—")
        self.reaction_center_head = self.mol_center  # å®Œæ•´çš„MolCenter
        
        # 2. åˆ†å­æ¢å¤å¤´ï¼šé‡‡ç”¨MolCLRçš„ä¸‰ç§å›¾å¢å¼ºç­–ç•¥
        print("  - åˆ†å­æ¢å¤å¤´ï¼šMolCLRä¸‰ç§å¢å¼ºç­–ç•¥")
        self.molecule_recovery_head = MoleculeRecoveryHead(
            input_dim=args.hidden_size,
            projection_dim=128,
            temperature=0.1
        )
        
        # 3. äº§ç‰©-åˆæˆå­å¯¹æ¯”å¤´ï¼šæ ¸å¿ƒåˆ›æ–°
        print("  - äº§ç‰©-åˆæˆå­å¯¹æ¯”å¤´ï¼šæ ¸å¿ƒåˆ›æ–°")
        self.product_synthon_contrastive_head = ProductSynthonContrastiveHead(
            product_input_dim=args.hidden_size,
            synthon_input_dim=args.hidden_size,
            projection_dim=128,
            temperature=0.1,
            fusion_method='attention'  # å¤„ç†å¤šåˆæˆå­
        )
        
        # æŒ‰ç…§è®¾è®¡æ–¹æ¡ˆï¼šæŸå¤±æƒé‡ L_total = L_base + L_recovery + 0.1 Ã— L_contrastive
        print("è®¾ç½®åŠ¨æ€è‡ªé€‚åº”å¤šä»»åŠ¡å­¦ä¹ æƒé‡ï¼ˆåŸºäºRetroExplainerï¼‰...")
        # å‚è€ƒRetroExplainerçš„DAMTç®—æ³•ï¼šåŠ¨æ€æ ¹æ®ä»»åŠ¡å­¦ä¹ è¿›åº¦è°ƒæ•´æƒé‡
        # åˆå§‹æƒé‡æŒ‰ç…§è®¾è®¡æ–¹æ¡ˆè®¾ç½®ï¼š[åŸºç¡€ä»»åŠ¡, åˆ†å­æ¢å¤, äº§ç‰©-åˆæˆå­å¯¹æ¯”] = [1.0, 1.0, 0.1]
        self.initial_task_weights = torch.tensor([1.0, 1.0, 0.1])
        
        # åŠ¨æ€æƒé‡å‚æ•°ï¼ˆå‚è€ƒRetroExplainerçš„DAMTï¼‰
        self.loss_queue_length = getattr(args, 'loss_queue_length', 50)  # æŸå¤±é˜Ÿåˆ—é•¿åº¦ï¼Œç”¨äºè®¡ç®—å¹³å‡å€¼
        self.temperature = getattr(args, 'weight_temperature', 2.0)      # æ¸©åº¦ç³»æ•°Ï„ï¼Œæ§åˆ¶æƒé‡åˆ†å¸ƒçš„é”åº¦
        self.min_weight = getattr(args, 'min_task_weight', 0.01)         # æœ€å°æƒé‡ï¼Œé˜²æ­¢æŸä¸ªä»»åŠ¡æƒé‡è¿‡å°
        self.max_weight = getattr(args, 'max_task_weight', 3.0)          # æœ€å¤§æƒé‡ï¼Œé˜²æ­¢æŸä¸ªä»»åŠ¡æƒé‡è¿‡å¤§
        
        # æŸå¤±å†å²è®°å½•é˜Ÿåˆ—ï¼ˆç”¨äºè®¡ç®—ä¸‹é™ç‡å’Œå¹³å‡å€¼ï¼‰
        self.loss_histories = {
            'center': [],     # åŸºç¡€ä»»åŠ¡æŸå¤±å†å²
            'recovery': [],   # åˆ†å­æ¢å¤æŸå¤±å†å²  
            'contrastive': [] # äº§ç‰©-åˆæˆå­å¯¹æ¯”æŸå¤±å†å²
        }
        
        # å½“å‰åŠ¨æ€æƒé‡ï¼ˆåˆå§‹å€¼ä¸ºè®¾è®¡æ–¹æ¡ˆæƒé‡ï¼‰
        self.register_buffer('task_weights', self.initial_task_weights.clone())
        
        # æƒé‡è°ƒæ•´è®¡æ•°å™¨
        self.weight_update_step = 0
        self.weight_update_frequency = getattr(args, 'weight_update_frequency', 5)  # æƒé‡æ›´æ–°é¢‘ç‡
        
        print(f"\nG2Retro-Pæ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼ˆè®¾è®¡æ–¹æ¡ˆ+åŠ¨æ€æƒé‡ï¼‰:")
        print(f"âœ“ å…±äº«ç¼–ç å™¨ï¼šGMPNï¼ˆæ¥è‡ªG2Retroï¼‰")
        print(f"âœ“ åŸºç¡€ä»»åŠ¡å¤´ï¼šG2Retroååº”ä¸­å¿ƒè¯†åˆ«æ¨¡å—")
        print(f"âœ“ åˆ†å­æ¢å¤å¤´ï¼šMolCLRä¸‰ç§å¢å¼ºç­–ç•¥")
        print(f"âœ“ äº§ç‰©-åˆæˆå­å¯¹æ¯”å¤´ï¼šæ ¸å¿ƒåˆ›æ–°")
        print(f"âœ“ åŠ¨æ€æƒé‡ç³»ç»Ÿï¼šåŸºäºRetroExplainer DAMTç®—æ³•")
        print(f"âœ“ åˆå§‹æƒé‡ï¼š[åŸºç¡€:{self.task_weights[0]:.3f}, æ¢å¤:{self.task_weights[1]:.3f}, å¯¹æ¯”:{self.task_weights[2]:.3f}]")
        print(f"âœ“ æƒé‡æ›´æ–°é¢‘ç‡ï¼šæ¯{self.weight_update_frequency}æ­¥")
        print(f"âœ“ æ¸©åº¦ç³»æ•°ï¼š{self.temperature}")
        print(f"âœ“ æŸå¤±é˜Ÿåˆ—é•¿åº¦ï¼š{self.loss_queue_length}")
        print(f"âœ“ è¯æ±‡è¡¨å¤§å°: {vocab.size()}")
        print(f"âœ“ åŸå­è¯æ±‡è¡¨å¤§å°: {avocab.size()}")
        print(f"âœ“ éšè—å±‚å¤§å°: {args.hidden_size}")

    def update_task_weights(self, current_losses):
        """
        åŠ¨æ€è‡ªé€‚åº”å¤šä»»åŠ¡å­¦ä¹ æƒé‡æ›´æ–°ï¼ˆåŸºäºRetroExplainerçš„DAMTç®—æ³•ï¼‰
        
        RetroExplainerçš„æ ¸å¿ƒæ€æƒ³ï¼šæ ¹æ®ä»»åŠ¡çš„å­¦ä¹ è¿›åº¦åŠ¨æ€è°ƒæ•´æƒé‡
        - å­¦ä¹ å›°éš¾çš„ä»»åŠ¡ï¼ˆæŸå¤±ä¸‹é™ç¼“æ…¢ï¼‰è·å¾—æ›´é«˜æƒé‡
        - å­¦ä¹ å®¹æ˜“çš„ä»»åŠ¡ï¼ˆæŸå¤±ä¸‹é™å¿«é€Ÿï¼‰è·å¾—è¾ƒä½æƒé‡
        - é€šè¿‡descent rateå’Œnormalization coefficientå®ç°è‡ªé€‚åº”å¹³è¡¡
        
        ç®—æ³•æ­¥éª¤ï¼š
        1. è®°å½•å½“å‰æŸå¤±åˆ°å†å²é˜Ÿåˆ—
        2. è®¡ç®—æ¯ä¸ªä»»åŠ¡çš„ä¸‹é™ç‡ r_i^t = l_i^{t-1} / l_i^t  
        3. è®¡ç®—å½’ä¸€åŒ–ç³»æ•° Î±_i^t = n / âˆ‘_{j=t-n}^{t-1} l_i^j
        4. è®¡ç®—åŠ¨æ€æƒé‡ w_i^t = softmax(r_i^t / Ï„) * Î±_i^t
        
        å‚æ•°ï¼š
            current_losses: å­—å…¸ï¼ŒåŒ…å«å½“å‰æ­¥çš„å„ä»»åŠ¡æŸå¤±
        """
        task_names = ['center', 'recovery', 'contrastive']
        
        # è®°å½•å½“å‰æŸå¤±åˆ°å†å²é˜Ÿåˆ—
        for i, task_name in enumerate(task_names):
            if task_name in current_losses:
                loss_value = current_losses[task_name].detach().cpu().item()
                self.loss_histories[task_name].append(loss_value)
                
                # ä¿æŒé˜Ÿåˆ—é•¿åº¦ä¸è¶…è¿‡è®¾å®šå€¼
                if len(self.loss_histories[task_name]) > self.loss_queue_length:
                    self.loss_histories[task_name].pop(0)
        
        # æƒé‡è°ƒæ•´é¢‘ç‡æ§åˆ¶
        self.weight_update_step += 1
        if self.weight_update_step % self.weight_update_frequency != 0:
            return
        
        # éœ€è¦è‡³å°‘2ä¸ªæŸå¤±å€¼æ‰èƒ½è®¡ç®—ä¸‹é™ç‡
        min_history_length = 2
        all_tasks_ready = all(
            len(self.loss_histories[task]) >= min_history_length 
            for task in task_names
        )
        
        if not all_tasks_ready:
            print(f"æƒé‡æ›´æ–°ï¼šç­‰å¾…æ›´å¤šæŸå¤±å†å²ï¼ˆå½“å‰é•¿åº¦: {[len(self.loss_histories[task]) for task in task_names]}ï¼‰")
            return
        
        try:
            # è®¡ç®—ä¸‹é™ç‡ r_i^t = l_i^{t-1} / l_i^t
            descent_rates = []
            normalization_coeffs = []
            
            for task_name in task_names:
                history = self.loss_histories[task_name]
                
                # è®¡ç®—ä¸‹é™ç‡ï¼ˆå½“å‰æŸå¤±ç›¸å¯¹äºå‰ä¸€æ¬¡æŸå¤±çš„æ¯”ç‡ï¼‰
                if len(history) >= 2:
                    current_loss = history[-1]
                    previous_loss = history[-2]
                    
                    # é˜²æ­¢é™¤é›¶å’Œè´Ÿæ•°
                    if current_loss > 0 and previous_loss > 0:
                        descent_rate = previous_loss / current_loss  # æ¯”ç‡è¶Šå¤§è¯´æ˜ä¸‹é™è¶Šæ˜æ˜¾
                    else:
                        descent_rate = 1.0
                else:
                    descent_rate = 1.0
                
                descent_rates.append(descent_rate)
                
                # è®¡ç®—å½’ä¸€åŒ–ç³»æ•° Î±_i^t = n / âˆ‘_{j=t-n}^{t-1} l_i^j
                # ä½¿ç”¨æœ€è¿‘nä¸ªæŸå¤±å€¼çš„å¹³å‡å€¼ä½œä¸ºå½’ä¸€åŒ–
                recent_losses = history[-min(len(history), self.loss_queue_length):]
                if len(recent_losses) > 0:
                    avg_loss = sum(recent_losses) / len(recent_losses)
                    normalization_coeff = 1.0 / max(avg_loss, 1e-8)  # é˜²æ­¢é™¤é›¶
                else:
                    normalization_coeff = 1.0
                
                normalization_coeffs.append(normalization_coeff)
            
            # è½¬æ¢ä¸ºå¼ é‡
            descent_rates = torch.tensor(descent_rates, dtype=torch.float32)
            normalization_coeffs = torch.tensor(normalization_coeffs, dtype=torch.float32)
            
            # åº”ç”¨æ¸©åº¦ç¼©æ”¾çš„softmaxè®¡ç®—æƒé‡åˆ†å¸ƒ
            # w_i^t = softmax(r_i^t / Ï„)
            scaled_rates = descent_rates / self.temperature
            weight_distribution = torch.softmax(scaled_rates, dim=0)
            
            # ç»“åˆå½’ä¸€åŒ–ç³»æ•°
            new_weights = weight_distribution * normalization_coeffs
            
            # é‡æ–°å½’ä¸€åŒ–æƒé‡ï¼Œç¡®ä¿æ€»å’Œåˆç†
            new_weights = new_weights / new_weights.sum() * self.initial_task_weights.sum()
            
            # åº”ç”¨æƒé‡é™åˆ¶
            new_weights = torch.clamp(new_weights, min=self.min_weight, max=self.max_weight)
            
            # æ›´æ–°æƒé‡
            old_weights = self.task_weights.clone()
            self.task_weights.copy_(new_weights)
            
            print(f"\n=== åŠ¨æ€æƒé‡æ›´æ–°ï¼ˆåŸºäºRetroExplainer DAMTï¼‰===")
            print(f"ä¸‹é™ç‡: {descent_rates.tolist()}")
            print(f"å½’ä¸€åŒ–ç³»æ•°: {normalization_coeffs.tolist()}")
            print(f"æƒé‡å˜åŒ–:")
            for i, task_name in enumerate(task_names):
                print(f"  {task_name}: {old_weights[i]:.4f} â†’ {new_weights[i]:.4f} (Î”{new_weights[i]-old_weights[i]:+.4f})")
            print(f"æƒé‡æ€»å’Œ: {new_weights.sum():.4f}")
            print("=" * 50)
            
        except Exception as e:
            print(f"æƒé‡æ›´æ–°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()

    def get_weight_statistics(self):
        """
        è·å–æƒé‡è°ƒæ•´ç»Ÿè®¡ä¿¡æ¯
        """
        stats = {
            'current_weights': self.task_weights.detach().cpu().numpy().tolist(),
            'initial_weights': self.initial_task_weights.numpy().tolist(),
            'weight_update_step': self.weight_update_step,
            'loss_history_lengths': {
                task: len(history) for task, history in self.loss_histories.items()
            }
        }
        return stats
    
    def reset_weight_adaptation(self):
        """
        é‡ç½®æƒé‡é€‚åº”ç³»ç»Ÿï¼ˆç”¨äºæ–°epochæˆ–è®­ç»ƒé‡å¯ï¼‰
        """
        print("é‡ç½®åŠ¨æ€æƒé‡é€‚åº”ç³»ç»Ÿ...")
        self.loss_histories = {task: [] for task in ['center', 'recovery', 'contrastive']}
        self.task_weights.copy_(self.initial_task_weights)
        self.weight_update_step = 0
        print(f"æƒé‡å·²é‡ç½®ä¸ºåˆå§‹å€¼: {self.initial_task_weights.tolist()}")
    
    def save_weight_adaptation_state(self):
        """
        ä¿å­˜æƒé‡é€‚åº”çŠ¶æ€ï¼ˆç”¨äºcheckpointingï¼‰
        """
        return {
            'task_weights': self.task_weights.detach().cpu(),
            'loss_histories': self.loss_histories.copy(),
            'weight_update_step': self.weight_update_step,
            'initial_task_weights': self.initial_task_weights,
            'loss_queue_length': self.loss_queue_length,
            'temperature': self.temperature,
            'min_weight': self.min_weight,
            'max_weight': self.max_weight,
            'weight_update_frequency': self.weight_update_frequency
        }
    
    def load_weight_adaptation_state(self, state):
        """
        åŠ è½½æƒé‡é€‚åº”çŠ¶æ€ï¼ˆç”¨äºcheckpointingï¼‰
        """
        self.task_weights.copy_(state['task_weights'])
        self.loss_histories = state['loss_histories']
        self.weight_update_step = state['weight_update_step']
        self.initial_task_weights = state['initial_task_weights']
        self.loss_queue_length = state['loss_queue_length']
        self.temperature = state['temperature']
        self.min_weight = state['min_weight']
        self.max_weight = state['max_weight']
        self.weight_update_frequency = state['weight_update_frequency']

    def encode_with_gmpn(self, tensors, classes=None, mol_trees=None):
        """
        ä½¿ç”¨å…±äº«çš„GMPNç¼–ç å™¨è¿›è¡Œç¼–ç 
        
        è®¾è®¡æ–¹æ¡ˆè¦æ±‚ï¼šGMPNé€šè¿‡å›¾æ¶ˆæ¯ä¼ é€’ç½‘ç»œï¼ˆGraph Message Passing Networkï¼‰æ¥å­¦ä¹ åˆ†å­ç»“æ„
        GMPNé€šè¿‡åœ¨åˆ†å­å›¾çš„åŸå­å’Œé”®ä¹‹é—´è¿­ä»£åœ°ä¼ é€’ä¿¡æ¯ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°æ•æ‰åˆ°æ¯ä¸ªåŸå­åŠå…¶å‘¨å›´çš„
        å±€éƒ¨åŒ–å­¦ç¯å¢ƒï¼Œä»è€Œç”Ÿæˆå¯Œæœ‰ç»“æ„ä¿¡æ¯çš„ç‰¹å¾è¡¨ç¤ºã€‚
        
        è¾“å…¥: åˆ†å­å›¾ G = (A, B)ï¼Œå…¶ä¸­ A æ˜¯åŸå­é›†åˆï¼ŒB æ˜¯åŒ–å­¦é”®é›†åˆ
        è¾“å‡º: åŸå­çº§åˆ«çš„åµŒå…¥è¡¨ç¤º aiï¼Œé”®çº§åˆ«çš„åµŒå…¥è¡¨ç¤º bijï¼Œä»¥åŠæ•´ä¸ªåˆ†å­å›¾çš„å…¨å±€è¡¨ç¤º h
        
        Args:
            mol_trees: MolTreeå¯¹è±¡åˆ—è¡¨ï¼Œç”¨äºMolCLRæ©ç æ”¯æŒ
        """
        # ä½¿ç”¨å…±äº«çš„GMPNç¼–ç å™¨ï¼Œæ”¯æŒMolCLRæ©ç 
        # ç¡®ä¿ä¼ å…¥çš„æ ¼å¼æ­£ç¡®
        if isinstance(tensors, list) and len(tensors) == 1:
            # å¦‚æœæ˜¯å•ä¸ªå›¾å¼ é‡çš„åˆ—è¡¨æ ¼å¼ï¼Œç›´æ¥ä¼ å…¥
            mol_embeds, atom_embeds, mess_embeds = self.shared_encoder(
                tensors,
                product=True, 
                classes=classes, 
                use_feature=True,
                mol_trees=mol_trees
            )
        else:
            # å¦‚æœæ˜¯ç›´æ¥çš„å›¾å¼ é‡ï¼ŒåŒ…è£…æˆåˆ—è¡¨
            mol_embeds, atom_embeds, mess_embeds = self.shared_encoder(
                [tensors],
                product=True, 
                classes=classes, 
                use_feature=True,
                mol_trees=mol_trees
            )
        return mol_embeds, atom_embeds, mess_embeds
    
    def merge_batch_tensors(self, tensor_list):
        """åˆå¹¶æ‰¹æ¬¡ä¸­çš„å¼ é‡æ•°æ®"""
        if not tensor_list:
            return []
        
        # è·å–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„ç»“æ„ä½œä¸ºå‚è€ƒ
        first_sample = tensor_list[0]
        if not isinstance(first_sample, (list, tuple)):
            return tensor_list
        
        # æŒ‰ä½ç½®åˆå¹¶æ‰€æœ‰æ ·æœ¬çš„å¼ é‡
        merged = []
        for i in range(len(first_sample)):
            if i < 6:  # å‰6ä¸ªæ˜¯éœ€è¦åˆå¹¶çš„å¼ é‡
                # æ”¶é›†æ‰€æœ‰æ ·æœ¬åœ¨ä½ç½®içš„å¼ é‡
                tensors_at_i = [sample[i] for sample in tensor_list]
                # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œéœ€è¦æ‹¼æ¥
                if isinstance(tensors_at_i[0], list):
                    merged_tensor = []
                    for t in tensors_at_i:
                        merged_tensor.extend(t)
                    merged.append(merged_tensor)
                else:
                    merged.append(tensors_at_i)
            else:
                # å…¶ä»–ä½ç½®çš„æ•°æ®ç›´æ¥ä½¿ç”¨ç¬¬ä¸€ä¸ªæ ·æœ¬çš„
                merged.append(first_sample[i])
        
        return merged
    # ========== è¾…åŠ©å‡½æ•°ç»“æŸ ==========


    def forward(self, batch, epoch=0):
        """
        æŒ‰ç…§è®¾è®¡æ–¹æ¡ˆçš„æ•°æ®æµç¨‹è¿›è¡Œå‰å‘ä¼ æ’­
        
        åœ¨é¢„è®­ç»ƒçš„æ¯ä¸€æ­¥ä¸­ï¼Œæ•°æ®æµç¨‹å¦‚ä¸‹ï¼š
        1. è¾“å…¥å¤„ç†: åŸºäºatom-mappingä»ååº”æ•°æ®ä¸­æå–äº§ç‰©åˆ†å­å›¾Gpå’Œå¯¹åº”çš„åˆæˆå­ç»„åˆGs
        2. æ•°æ®å¢å¼º: å¯¹åŸå§‹äº§ç‰©åˆ†å­å›¾åº”ç”¨MolCLRå¢å¼ºç­–ç•¥ï¼Œç”Ÿæˆä¸€ä¸ªè¢«"ç ´å"çš„ç‰ˆæœ¬Gp_aug
        3. ä¸‰è·¯å…±äº«ç¼–ç : 
           - åŸå§‹äº§ç‰©å›¾ Gp è¾“å…¥GMPNç¼–ç å™¨ â†’ h_product
           - å¢å¼ºäº§ç‰©å›¾ Gp_aug è¾“å…¥GMPNç¼–ç å™¨ â†’ h_augmented 
           - åˆæˆå­ç»„åˆ Gs è¾“å…¥GMPNç¼–ç å™¨ â†’ h_synthons
        4. å¹¶è¡Œè®¡ç®—:
           - h_product è¢«é€å…¥åŸºç¡€ä»»åŠ¡å¤´å’Œäº§ç‰©-åˆæˆå­å¯¹æ¯”å¤´
           - h_augmented è¢«é€å…¥åˆ†å­æ¢å¤å¤´
           - h_synthons è¢«é€å…¥äº§ç‰©-åˆæˆå­å¯¹æ¯”å¤´
        5. æŸå¤±è®¡ç®—ä¸åå‘ä¼ æ’­: ä¸‰ä¸ªä»»åŠ¡å¤´åˆ†åˆ«è®¡ç®—å‡ºå„è‡ªçš„æŸå¤±
        """
        losses = {}
        metrics = {}
        # è·å–å¼ é‡æ•°æ® - æ³¨æ„è¿™é‡Œçš„æ•°æ®ç»“æ„
        prod_tensors = batch['prod_tensors']      # Gp
        aug_tensors = batch['aug_tensors']        # Gp_aug  
        synthon_tensors = batch['synthon_tensors'] # Gs
        react_tensors = batch['react_tensors']     # ç”¨äºåŸºç¡€ä»»åŠ¡
    
        # æ£€æŸ¥æ•°æ®ç»“æ„å¹¶æ­£ç¡®è§£åŒ…
        # MolTree.tensorizeè¿”å›æ ¼å¼: 
        # - product=True: ([graph_batchG], [graph_tensors], None, all_orders)
        # - product=False: (react_graphs, react_tensors, react_orders)
        # æˆ‘ä»¬éœ€è¦æå–å¼ é‡éƒ¨åˆ†ï¼Œè·³è¿‡DiGraphå¯¹è±¡
        
        # è°ƒè¯•ï¼šæ£€æŸ¥å¼ é‡ç»“æ„
        print(f"DEBUG: prod_tensors type: {type(prod_tensors)}")
        if isinstance(prod_tensors, tuple):
            print(f"DEBUG: prod_tensors length: {len(prod_tensors)}")
            for i, item in enumerate(prod_tensors):
                print(f"DEBUG: prod_tensors[{i}] type: {type(item)}")
                if isinstance(item, list) and len(item) > 0:
                    print(f"DEBUG: prod_tensors[{i}][0] type: {type(item[0])}")
        
        # åˆ›å»ºç»Ÿä¸€çš„æ•°æ®å¤„ç†å‡½æ•°ï¼Œç¡®ä¿æ ¼å¼å®Œå…¨å¯¹é½
        def process_tensor_data(raw_tensors, is_product=True):
            """
            ç»Ÿä¸€å¤„ç†å¼ é‡æ•°æ®ï¼Œç¡®ä¿æ ¼å¼ä¸mol_enc.pyæœŸæœ›çš„å®Œå…¨ä¸€è‡´
            
            Args:
                raw_tensors: MolTree.tensorizeè¿”å›çš„tensor_dataéƒ¨åˆ†ï¼ˆ4å…ƒç»„ï¼‰
                is_product: æ˜¯å¦ä¸ºäº§ç‰©æ•°æ®
            
            Returns:
                å¤„ç†åçš„å¼ é‡ï¼Œæ ¼å¼ä¸mol_enc.pyæœŸæœ›çš„ä¸€è‡´
            """
            print(f"DEBUG: raw_tensors type: {type(raw_tensors)}")
            print(f"DEBUG: raw_tensors length: {len(raw_tensors)}")
            
            # æ­¥éª¤1ï¼šä»MolTree.tensorizeçš„tensor_dataä¸­æå–å›¾å¼ é‡
            if isinstance(raw_tensors, tuple) and len(raw_tensors) == 4:
                # raw_tensorsæ˜¯tensor_data: ([graph_batchG], [graph_tensors], tree_tensors, all_orders)
                graph_batchG_list, graph_tensors_list, tree_tensors, all_orders = raw_tensors
                
                print(f"DEBUG: graph_tensors_list type: {type(graph_tensors_list)}")
                print(f"DEBUG: graph_tensors_list length: {len(graph_tensors_list)}")
                
                # æå–ç¬¬ä¸€ä¸ªå›¾çš„å¼ é‡ï¼ˆ7å…ƒç»„ï¼‰
                if isinstance(graph_tensors_list, list) and len(graph_tensors_list) > 0:
                    graph_tensors = graph_tensors_list[0]  # è¿™æ˜¯7å…ƒç»„
                    print(f"DEBUG: graph_tensors type: {type(graph_tensors)}")
                    print(f"DEBUG: graph_tensors length: {len(graph_tensors)}")
                else:
                    raise ValueError(f"graph_tensors_listæ ¼å¼é”™è¯¯: {type(graph_tensors_list)}")
            else:
                raise ValueError(f"raw_tensorsæ ¼å¼é”™è¯¯: æœŸæœ›4å…ƒç»„ï¼Œå¾—åˆ°: {type(raw_tensors)}, é•¿åº¦: {len(raw_tensors) if hasattr(raw_tensors, '__len__') else 'N/A'}")
            
            # æ­¥éª¤2ï¼šéªŒè¯å›¾å¼ é‡æ ¼å¼
            if not isinstance(graph_tensors, (list, tuple)) or len(graph_tensors) != 7:
                raise ValueError(f"æœŸæœ›7å…ƒç»„å›¾å¼ é‡ï¼Œä½†å¾—åˆ°: {type(graph_tensors)}, é•¿åº¦: {len(graph_tensors) if hasattr(graph_tensors, '__len__') else 'N/A'}")
            
            # æ­¥éª¤3ï¼šå°†å¼ é‡ç§»åŠ¨åˆ°CUDAå¹¶ç¡®ä¿æ­£ç¡®çš„æ•°æ®ç±»å‹
            processed_tensors = []
            for i, tensor in enumerate(graph_tensors):
                if tensor is None:
                    processed_tensors.append(None)
                elif i == 6:  # scopeä¿æŒåŸæ ·ï¼ˆé€šå¸¸æ˜¯åˆ—è¡¨ï¼‰
                    processed_tensors.append(tensor)
                elif isinstance(tensor, torch.Tensor):
                    # ç¡®ä¿åœ¨æ­£ç¡®è®¾å¤‡ä¸Šä¸”ä¸ºé•¿æ•´å‹
                    processed_tensors.append(tensor.to(device).long())
                else:
                    # è½¬æ¢ä¸ºå¼ é‡
                    processed_tensors.append(torch.tensor(tensor, device=device, dtype=torch.long))
            
            # æ­¥éª¤4ï¼šéªŒè¯æœ€ç»ˆç»“æœ
            if len(processed_tensors) != 7:
                raise ValueError(f"å¤„ç†åçš„å¼ é‡é•¿åº¦ä¸æ­£ç¡®: {len(processed_tensors)}")
            
            return processed_tensors
        
        # ä½¿ç”¨ç»Ÿä¸€å‡½æ•°å¤„ç†æ‰€æœ‰æ•°æ®
        try:
            prod_tensors = process_tensor_data(prod_tensors, is_product=True)
            aug_tensors = process_tensor_data(aug_tensors, is_product=True) 
            synthon_tensors = process_tensor_data(synthon_tensors, is_product=False)
            
            print(f"âœ“ æ•°æ®å¤„ç†æˆåŠŸ - äº§ç‰©: {len(prod_tensors)}å…ƒç»„, å¢å¼º: {len(aug_tensors)}å…ƒç»„, åˆæˆå­: {len(synthon_tensors)}å…ƒç»„")
            
        except Exception as e:
            print(f"âŒ æ•°æ®å¤„ç†å¤±è´¥: {e}")
            # è¿”å›é›¶æŸå¤±é¿å…è®­ç»ƒä¸­æ–­
            return {
                'total': torch.tensor(0.0, device=device, requires_grad=True),
                'center': torch.tensor(0.0, device=device, requires_grad=True),
                'recovery': torch.tensor(0.0, device=device, requires_grad=True),
                'contrastive': torch.tensor(0.0, device=device, requires_grad=True)
            }, {}        
        batch_size = batch['batch_size']
        
        try:
            # æŒ‰ç…§è®¾è®¡æ–¹æ¡ˆï¼šä¸‰è·¯å…±äº«ç¼–ç   
            # ä¸ºMolCLRæ©ç å‡†å¤‡MolTreeå¯¹è±¡
            product_trees = batch.get('prod_trees', [])
            augmented_trees = batch.get('aug_trees', [])  # å¢å¼ºçš„åˆ†å­æ ‘ï¼ŒåŒ…å«æ©ç ä¿¡æ¯
            synthon_trees = batch.get('synthon_trees', [])
            
            h_product, atom_embeds_prod, mess_embeds_prod = self.encode_with_gmpn(
                prod_tensors, mol_trees=product_trees)
            h_augmented, atom_embeds_aug, mess_embeds_aug = self.encode_with_gmpn(
                aug_tensors, mol_trees=augmented_trees)  # ä¼ é€’å¢å¼ºçš„åˆ†å­æ ‘
            h_synthons, atom_embeds_syn, mess_embeds_syn = self.encode_with_gmpn(
                synthon_tensors, mol_trees=synthon_trees)
            
            # æŒ‰ç…§è®¾è®¡æ–¹æ¡ˆï¼šå¹¶è¡Œè®¡ç®—ä¸‰ä¸ªä»»åŠ¡
            
            # ä»»åŠ¡1ï¼šåŸºç¡€ä»»åŠ¡ï¼ˆååº”ä¸­å¿ƒè¯†åˆ«ï¼‰
            try:
                # è®¾è®¡æ–¹æ¡ˆè¦æ±‚ï¼šå®Œå…¨ä¿ç•™G2Retroçš„ååº”ä¸­å¿ƒè¯†åˆ«æœºåˆ¶
                # ä½¿ç”¨çœŸæ­£çš„G2Retro MolCenteræ¨¡å—è¿›è¡Œååº”ä¸­å¿ƒè¯†åˆ«
                
                # å‡†å¤‡ååº”ä¸­å¿ƒè¯†åˆ«æ‰€éœ€çš„å®Œæ•´æ•°æ®
                # ä»æ‰¹æ¬¡æ•°æ®ä¸­æå–å¿…è¦ä¿¡æ¯
                product_orders = []
                product_trees = batch.get('prod_trees', [])
                
                # ä»äº§ç‰©å¼ é‡ä¸­æ­£ç¡®æå–æ‰€éœ€ä¿¡æ¯
                # MolTree.tensorizeæ€»æ˜¯è¿”å›æ ‡å‡†çš„7ä¸ªå¼ é‡ï¼š
                # [atom_tensors, bond_tensors, tree_tensors, word_tensors, 
                #  mess_dict, local_dict, scope_tensors]
                product_bond_tensors = prod_tensors[1]   # bond tensor (ç´¢å¼•1)
                product_scope_tensors = prod_tensors[6]  # scope tensor (ç´¢å¼•6)
                
                # æå–æ¯ä¸ªæ ·æœ¬çš„å®Œæ•´orderä¿¡æ¯  
                product_orders = []
                valid_order_count = 0
                
                for i, pretrain_info in enumerate(batch['pretrain_infos']):
                    if 'product_orders' in pretrain_info and pretrain_info['product_orders'] is not None:
                        product_orders.append(pretrain_info['product_orders'])
                        valid_order_count += 1
                    else:
                        # å¦‚æœæ²¡æœ‰orderä¿¡æ¯ï¼Œä»äº§ç‰©æ ‘ä¸­æå–
                        if i < len(product_trees):
                            tree = product_trees[i]
                            if hasattr(tree, 'order') and tree.order is not None:
                                # ä»æ ‘ä¸­æå–å®Œæ•´çš„orderä¿¡æ¯
                                bond_order, atom_order, ring_order, change_order = tree.order
                                product_orders.append((bond_order, atom_order, ring_order, change_order))
                                valid_order_count += 1
                            else:
                                # é¢„è®­ç»ƒé˜¶æ®µï¼šåˆ›å»ºç©ºorderä¿¡æ¯ä½œä¸ºå ä½ç¬¦
                                # è¿™æ ·å¯ä»¥è®©predict_centersæ­£å¸¸è¿è¡Œï¼Œä½†ä¸ä¼šäº§ç”Ÿæœ‰æ•ˆçš„ç›‘ç£ä¿¡å·
                                product_orders.append(([], [], [], []))
                        else:
                            product_orders.append(([], [], [], []))
                
                if valid_order_count < len(product_orders):
                    print(f"    è­¦å‘Š: {len(product_orders)-valid_order_count}/{len(product_orders)} æ ·æœ¬ç¼ºå°‘orderä¿¡æ¯")
                
                # è°ƒç”¨G2Retroçš„ååº”ä¸­å¿ƒè¯†åˆ«ï¼ˆä½¿ç”¨å®Œæ•´å‚æ•°ï¼‰
                center_loss, center_acc, num_samples, bond_data, atom_data = self.reaction_center_head.predict_centers(
                    product_bond_tensors,     # äº§ç‰©é”®å¼ é‡
                    h_product,               # äº§ç‰©åµŒå…¥å‘é‡
                    atom_embeds_prod,        # äº§ç‰©åŸå­å‘é‡
                    mess_embeds_prod,        # äº§ç‰©æ¶ˆæ¯å‘é‡
                    product_trees,           # äº§ç‰©åˆ†å­æ ‘åˆ—è¡¨
                    product_scope_tensors,   # äº§ç‰©å›¾èŒƒå›´å¼ é‡
                    product_orders           # äº§ç‰©orderä¿¡æ¯
                )
                
                print(f"    Center - Loss: {center_loss.item():.4f}, Acc: {center_acc:.4f}")
                
                # å¤„ç†bond changeå’Œatom chargeé¢„æµ‹
                if bond_data[0] is not None and len(bond_data[0]) > 0:
                    bond_change_hiddens, bond_change_labels = bond_data
                    bond_change_logits = self.reaction_center_head.W_bc(bond_change_hiddens)
                    bond_change_loss = self.reaction_center_head.bond_charge_loss(bond_change_logits, bond_change_labels)
                    center_loss = center_loss + bond_change_loss
                    
                if atom_data[0] is not None and len(atom_data[0]) > 0:
                    atom_charge_hiddens, atom_charge_labels = atom_data
                    atom_charge_logits = self.reaction_center_head.W_tac(atom_charge_hiddens)
                    atom_charge_loss = self.reaction_center_head.atom_charge_loss(atom_charge_logits, atom_charge_labels)
                    center_loss = center_loss + atom_charge_loss
                
            except Exception as e:
                print(f"    åŸºç¡€ä»»åŠ¡é”™è¯¯: {e}")
                center_loss = torch.zeros(1, device=device, requires_grad=True).squeeze()
                center_acc = 0.0
            
            losses['center'] = center_loss
            metrics['center_acc'] = center_acc
            
            # ä»»åŠ¡2ï¼šåˆ†å­æ¢å¤ä»»åŠ¡
            if len(batch['augmented_data']) > 0:
                # æŒ‰ç…§è®¾è®¡æ–¹æ¡ˆï¼šh_augmentedè¢«é€å…¥åˆ†å­æ¢å¤å¤´
                # åˆ†å­æ¢å¤ä»»åŠ¡çš„ç›®æ ‡æ˜¯ä»å¢å¼ºçš„è¡¨ç¤ºæ¢å¤åŸå§‹è¡¨ç¤º
                recovery_loss, recovery_acc = self.molecule_recovery_head(
                    original_embeddings=h_product,      # åŸå§‹åˆ†å­è¡¨ç¤ºä½œä¸ºç›®æ ‡
                    augmented_embeddings=h_augmented,   # å¢å¼ºåˆ†å­è¡¨ç¤ºä½œä¸ºè¾“å…¥
                    augmented_data=batch['augmented_data'],
                    pretrain_infos=batch['pretrain_infos']
                )
                losses['recovery'] = recovery_loss
                metrics['recovery_acc'] = recovery_acc
                print(f"    Recovery - Loss: {recovery_loss.item():.4f}, Acc: {recovery_acc:.4f}")
            else:
                losses['recovery'] = torch.tensor(0.0, device=device, requires_grad=True)
                metrics['recovery_acc'] = 0.0
            
            # ä»»åŠ¡3ï¼šäº§ç‰©-åˆæˆå­å¯¹æ¯”å­¦ä¹ ï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼‰
            
            contrastive_loss, contrastive_acc = self.product_synthon_contrastive_head(
                h_product,    # äº§ç‰©è¡¨ç¤º [batch_size, hidden_size]
                h_synthons,   # åˆæˆå­è¡¨ç¤º [batch_size, hidden_size]
                batch['pretrain_infos']
            )
            
            losses['contrastive'] = contrastive_loss
            metrics['contrastive_acc'] = contrastive_acc
            print(f"    Contrastive - Loss: {contrastive_loss.item():.4f}, Acc: {contrastive_acc:.4f}")
            
            # åŠ¨æ€æ›´æ–°ä»»åŠ¡æƒé‡ï¼ˆåŸºäºRetroExplainerçš„DAMTï¼‰
            self.update_task_weights(losses)
            
            # è®¡ç®—æ€»æŸå¤±ï¼ˆåŠ¨æ€æƒé‡ï¼‰
            total_loss = (
                self.task_weights[0] * losses['center'] + 
                self.task_weights[1] * losses['recovery'] + 
                self.task_weights[2] * losses['contrastive']
            )
            print(f"    Total Loss: {total_loss.item():.4f} "
                  f"[Weights: {self.task_weights[0]:.3f}, {self.task_weights[1]:.3f}, {self.task_weights[2]:.3f}]")
            
            losses['total'] = total_loss
            metrics['task_weights'] = self.task_weights.detach().cpu().numpy()
            
            # è®°å½•æƒé‡å˜åŒ–ç»Ÿè®¡
            metrics['weight_center'] = self.task_weights[0].item()
            metrics['weight_recovery'] = self.task_weights[1].item()  
            metrics['weight_contrastive'] = self.task_weights[2].item()
            
        except Exception as e:
            print(f"å‰å‘ä¼ æ’­é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            # è¿”å›é›¶æŸå¤±é¿å…è®­ç»ƒä¸­æ–­
            losses = {
                'total': torch.tensor(0.0, device=device, requires_grad=True),
                'center': torch.tensor(0.0, device=device, requires_grad=True),
                'recovery': torch.tensor(0.0, device=device, requires_grad=True),
                'contrastive': torch.tensor(0.0, device=device, requires_grad=True)
            }
            metrics = {
                'center_acc': 0.0,
                'recovery_acc': 0.0,
                'contrastive_acc': 0.0,
                'task_weights': np.array([1.0, 1.0, 0.1])
            }
        
        return losses, metrics

class G2RetroPDesignAlignedTrainer:
    """
    ç¬¦åˆè®¾è®¡æ–¹æ¡ˆçš„è®­ç»ƒå™¨
    
    è®¾è®¡æ–¹æ¡ˆè¦æ±‚ï¼š
    - å¾®è°ƒé˜¶æ®µ: åœ¨é¢„è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹å°†ç§»é™¤è¾…åŠ©ä»»åŠ¡å¤´ï¼ˆåˆ†å­æ¢å¤ä¸äº§ç‰©-åˆæˆå­å¯¹æ¯”ï¼‰ï¼Œ
      ä»…ä¿ç•™ç»è¿‡å……åˆ†å­¦ä¹ çš„å…±äº«ç¼–ç å™¨å’ŒåŸºç¡€ä»»åŠ¡å¤´ã€‚ç„¶åï¼Œä½¿ç”¨é¢„è®­ç»ƒå¥½çš„ç¼–ç å™¨æƒé‡
      è¿›è¡Œåˆå§‹åŒ–ï¼Œåœ¨ç‰¹å®šçš„ä¸‹æ¸¸æ•°æ®é›†ï¼ˆå¦‚USPTO-50Kï¼‰ä¸Šè¿›è¡Œé«˜æ•ˆçš„å¾®è°ƒã€‚
    """
    def __init__(self, model, train_loader, val_loader, args):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.args = args
        
        # ä¼˜åŒ–å™¨
        self.optimizer = optim.Adam(
            model.parameters(),
            lr=args.learning_rate,
            weight_decay=args.weight_decay
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = optim.lr_scheduler.StepLR(
            self.optimizer,
            step_size=args.step_size,
            gamma=args.gamma
        )
        
        self.best_val_loss = float('inf')
        self.patience_counter = 0
        
        # åŠ¨æ€æƒé‡é€‚åº”è®¾ç½®
        self.reset_weights_per_epoch = getattr(args, 'reset_weights_per_epoch', False)  # æ˜¯å¦æ¯epoché‡ç½®æƒé‡

    def train_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        
        # å¯é€‰åœ°åœ¨æ¯ä¸ªepochå¼€å§‹æ—¶é‡ç½®åŠ¨æ€æƒé‡é€‚åº”
        if self.reset_weights_per_epoch and epoch > 0:
            print(f"\n=== Epoch {epoch}: é‡ç½®åŠ¨æ€æƒé‡é€‚åº”ç³»ç»Ÿ ===")
            self.model.reset_weight_adaptation()
        
        # åœ¨epochå¼€å§‹æ—¶æ˜¾ç¤ºå½“å‰æƒé‡çŠ¶æ€
        if epoch % 5 == 0:  # æ¯5ä¸ªepochæ˜¾ç¤ºä¸€æ¬¡æƒé‡ç»Ÿè®¡
            weight_stats = self.model.get_weight_statistics()
            print(f"\n=== Epoch {epoch}: åŠ¨æ€æƒé‡é€‚åº”çŠ¶æ€ ===")
            print(f"å½“å‰æƒé‡: {weight_stats['current_weights']}")
            print(f"åˆå§‹æƒé‡: {weight_stats['initial_weights']}")
            print(f"æƒé‡æ›´æ–°æ­¥æ•°: {weight_stats['weight_update_step']}")
            print(f"æŸå¤±å†å²é•¿åº¦: {weight_stats['loss_history_lengths']}")
            print("=" * 50)
        
        total_losses = defaultdict(float)
        total_metrics = defaultdict(float)
        num_batches = 0
        
        for batch_idx, batch in enumerate(self.train_loader):
            if batch is None:
                continue
                
            self.optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            losses, metrics = self.model(batch, epoch)
            
            # åå‘ä¼ æ’­
            losses['total'].backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            self.optimizer.step()
            
            # ç´¯è®¡ç»Ÿè®¡
            for key, value in losses.items():
                if isinstance(value, torch.Tensor):
                    total_losses[key] += value.item()
                else:
                    total_losses[key] += value
                    
            for key, value in metrics.items():
                if isinstance(value, np.ndarray):
                    if key not in total_metrics:
                        total_metrics[key] = np.zeros_like(value)
                    total_metrics[key] += value
                else:
                    total_metrics[key] += value
            
            num_batches += 1
            
            if batch_idx % 5 == 0:
                print(f"Epoch {epoch}, Batch {batch_idx}/{len(self.train_loader)} - "
                      f"Loss: {losses['total'].item():.4f} "
                      f"[Center: {losses['center'].item():.4f}, "
                      f"Recovery: {losses['recovery'].item():.4f}, "
                      f"Contrast: {losses['contrastive'].item():.4f}]")
                if 'task_weights' in metrics:
                    weights = metrics['task_weights']
                    print(f"  æƒé‡: [{weights[0]:.3f}, {weights[1]:.3f}, {weights[2]:.3f}]")
        
        # è®¡ç®—å¹³å‡å€¼
        if num_batches > 0:
            avg_losses = {k: v/num_batches for k, v in total_losses.items()}
            avg_metrics = {}
            for k, v in total_metrics.items():
                if isinstance(v, np.ndarray):
                    avg_metrics[k] = v / num_batches
                else:
                    avg_metrics[k] = v / num_batches
        else:
            avg_losses = {}
            avg_metrics = {}
        
        return avg_losses, avg_metrics

    def validate(self, epoch):
        """éªŒè¯"""
        self.model.eval()
        
        total_losses = defaultdict(float)
        total_metrics = defaultdict(float)
        num_batches = 0
        
        with torch.no_grad():
            for batch in self.val_loader:
                if batch is None:
                    continue
                    
                losses, metrics = self.model(batch, epoch)
                
                for key, value in losses.items():
                    if isinstance(value, torch.Tensor):
                        total_losses[key] += value.item()
                    else:
                        total_losses[key] += value
                        
                for key, value in metrics.items():
                    if isinstance(value, np.ndarray):
                        if key not in total_metrics:
                            total_metrics[key] = np.zeros_like(value)
                        total_metrics[key] += value
                    else:
                        total_metrics[key] += value
                
                num_batches += 1
        
        if num_batches == 0:
            return {}, {}
            
        avg_losses = {k: v/num_batches for k, v in total_losses.items()}
        avg_metrics = {}
        for k, v in total_metrics.items():
            if isinstance(v, np.ndarray):
                avg_metrics[k] = v / num_batches
            else:
                avg_metrics[k] = v / num_batches
        
        return avg_losses, avg_metrics

    def train(self):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        print("\n" + "="*80)
        print("å¼€å§‹G2Retro-Pé¢„è®­ç»ƒï¼ˆè®¾è®¡æ–¹æ¡ˆå®Œå…¨å¯¹é½ï¼‰")
        print("="*80)
        
        for epoch in range(self.args.epochs):
            print(f"\n{'='*20} Epoch {epoch+1}/{self.args.epochs} {'='*20}")
            
            # è®­ç»ƒ
            train_losses, train_metrics = self.train_epoch(epoch)
            
            # éªŒè¯
            val_losses, val_metrics = self.validate(epoch)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            self.scheduler.step()
            
            # æ‰“å°è¯¦ç»†è®­ç»ƒç»Ÿè®¡
            print(f"\n{'='*60}")
            print(f"Epoch {epoch+1} è®­ç»ƒç»“æœæ±‡æ€»:")
            print(f"{'='*60}")
            print(f"æŸå¤±å€¼:")
            print(f"  ä¸­å¿ƒè¯†åˆ«æŸå¤±: {train_losses.get('center', 0):.4f}")
            print(f"  åˆ†å­æ¢å¤æŸå¤±: {train_losses.get('recovery', 0):.4f}")
            print(f"  å¯¹æ¯”å­¦ä¹ æŸå¤±: {train_losses.get('contrastive', 0):.4f}")
            print(f"  æ€»æŸå¤±: {train_losses.get('total', 0):.4f}")
            print(f"å‡†ç¡®ç‡:")
            print(f"  ä¸­å¿ƒè¯†åˆ«å‡†ç¡®ç‡: {train_metrics.get('center_acc', 0):.4f}")
            print(f"  åˆ†å­æ¢å¤å‡†ç¡®ç‡: {train_metrics.get('recovery_acc', 0):.4f}")
            print(f"  å¯¹æ¯”å­¦ä¹ å‡†ç¡®ç‡: {train_metrics.get('contrastive_acc', 0):.4f}")
            print(f"åŠ¨æ€æƒé‡:")
            print(f"  å½“å‰æƒé‡: [Center: {self.model.task_weights[0]:.3f}, Recovery: {self.model.task_weights[1]:.3f}, Contrastive: {self.model.task_weights[2]:.3f}]")
            print(f"  æƒé‡æ›´æ–°æ­¥æ•°: {self.model.weight_update_step}")
            
            if val_losses:
                print(f"\néªŒè¯ç»“æœ:")
                print(f"æŸå¤±å€¼:")
                print(f"  ä¸­å¿ƒè¯†åˆ«æŸå¤±: {val_losses.get('center', 0):.4f}")
                print(f"  åˆ†å­æ¢å¤æŸå¤±: {val_losses.get('recovery', 0):.4f}")
                print(f"  å¯¹æ¯”å­¦ä¹ æŸå¤±: {val_losses.get('contrastive', 0):.4f}")
                print(f"  æ€»æŸå¤±: {val_losses.get('total', 0):.4f}")
                print(f"å‡†ç¡®ç‡:")
                print(f"  ä¸­å¿ƒè¯†åˆ«å‡†ç¡®ç‡: {val_metrics.get('center_acc', 0):.4f}")
                print(f"  åˆ†å­æ¢å¤å‡†ç¡®ç‡: {val_metrics.get('recovery_acc', 0):.4f}")
                print(f"  å¯¹æ¯”å­¦ä¹ å‡†ç¡®ç‡: {val_metrics.get('contrastive_acc', 0):.4f}")
            
            print(f"{'='*60}\n")
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            if epoch % 2 == 0:
                self.save_checkpoint(epoch, train_losses, val_losses)
            
            # æ—©åœæ£€æŸ¥
            current_val_loss = val_losses.get('total', float('inf'))
            if current_val_loss < self.best_val_loss:
                self.best_val_loss = current_val_loss
                self.patience_counter = 0
                self.save_checkpoint(epoch, train_losses, val_losses, is_best=True)
            else:
                self.patience_counter += 1
                
            if self.patience_counter >= self.args.patience:
                print(f"æ—©åœäºepoch {epoch+1}")
                break

    def save_checkpoint(self, epoch, train_losses, val_losses, is_best=False):
        """ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆåŒ…å«åŠ¨æ€æƒé‡çŠ¶æ€ï¼‰"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'train_losses': train_losses,
            'val_losses': val_losses,
            'best_val_loss': self.best_val_loss,
            'weight_adaptation_state': self.model.save_weight_adaptation_state()  # ä¿å­˜åŠ¨æ€æƒé‡çŠ¶æ€
        }
        
        save_path = f"checkpoints_g2retro_p_design_aligned/checkpoint_epoch_{epoch}.pt"
        if is_best:
            save_path = "checkpoints_g2retro_p_design_aligned/best_model.pt"
            
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        torch.save(checkpoint, save_path)
        print(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: {save_path}")

# è®­ç»ƒå‚æ•°ç±»
class Args:
    def __init__(self):
        # æ¨¡å‹å‚æ•°ï¼ˆä¸G2Retroä¿æŒä¸€è‡´ï¼‰
        self.hidden_size = 300
        self.latent_size = 300
        self.depthT = 3
        self.depthG = 3
        self.use_feature = True
        self.use_tree = True
        self.network_type = "gru"
        self.use_node_embed = False
        self.use_class = False
        self.use_atomic = False
        self.sum_pool = False
        self.use_brics = False
        self.use_latent_attachatom = False
        self.use_mess = True
        
        # è®­ç»ƒå‚æ•°
        self.batch_size = 4  # å°æ‰¹æ¬¡é€‚åº”GPUå†…å­˜
        self.learning_rate = 1e-4
        self.weight_decay = 1e-5
        self.epochs = 3  # æ¼”ç¤ºç”¨å°‘é‡epoch
        self.step_size = 2
        self.gamma = 0.5
        self.patience = 2
        
        # åŠ¨æ€æƒé‡é€‚åº”å‚æ•°ï¼ˆåŸºäºRetroExplainer DAMTï¼‰
        self.reset_weights_per_epoch = False  # æ˜¯å¦æ¯epoché‡ç½®æƒé‡
        self.weight_update_frequency = 5      # æƒé‡æ›´æ–°é¢‘ç‡
        self.weight_temperature = 2.0         # æ¸©åº¦ç³»æ•°Ï„
        self.loss_queue_length = 50           # æŸå¤±é˜Ÿåˆ—é•¿åº¦
        self.min_task_weight = 0.01           # æœ€å°ä»»åŠ¡æƒé‡
        self.max_task_weight = 3.0            # æœ€å¤§ä»»åŠ¡æƒé‡
        
        # æ•°æ®é›†å‚æ•°
        self.use_small_dataset = False        # é»˜è®¤ä½¿ç”¨å®Œæ•´æ•°æ®é›†

def main():
    """ä¸»å‡½æ•°"""
    print("="*80)
    print("G2Retro-P è®¾è®¡æ–¹æ¡ˆå®Œå…¨å¯¹é½å®ç°")
    print("ä¸¥æ ¼æŒ‰ç…§'åŸºäºå¤šä»»åŠ¡é¢„è®­ç»ƒçš„åŠæ¨¡æ¿é€†åˆæˆæ¨¡å‹è®¾è®¡æ–¹æ¡ˆ'å®ç°")
    print("="*80)
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    random.seed(42)
    
    # å‚æ•°è®¾ç½®
    args = Args()
    
    # å‘½ä»¤è¡Œå‚æ•°è§£æ
    if '--small' in sys.argv or '--small-dataset' in sys.argv or '--use_small_dataset' in sys.argv:
        args.use_small_dataset = True
        print("ğŸš€ å‘½ä»¤è¡ŒæŒ‡å®šä½¿ç”¨å°æ•°æ®é›†æ¨¡å¼!")
    
    # è§£æå…¶ä»–å‚æ•°
    for i, arg in enumerate(sys.argv):
        if arg == '--epochs' and i + 1 < len(sys.argv):
            args.epochs = int(sys.argv[i + 1])
            print(f"è®¾ç½®epochs: {args.epochs}")
        elif arg == '--batch_size' and i + 1 < len(sys.argv):
            args.batch_size = int(sys.argv[i + 1])
            print(f"è®¾ç½®batch_size: {args.batch_size}")
    
    if '--help' in sys.argv or '-h' in sys.argv:
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("  python train_g2retro_p_design_aligned.py              # ä½¿ç”¨å®Œæ•´æ•°æ®é›†")
        print("  python train_g2retro_p_design_aligned.py --small      # ä½¿ç”¨å°æ•°æ®é›†å¿«é€Ÿæµ‹è¯•")
        print("  python train_g2retro_p_design_aligned.py --use_small_dataset  # ä½¿ç”¨å°æ•°æ®é›†å¿«é€Ÿæµ‹è¯•")
        print("\nå‚æ•°è¯´æ˜:")
        print("  --small, --small-dataset, --use_small_dataset    ä½¿ç”¨å°æ•°æ®é›†è¿›è¡Œå¿«é€Ÿæµ‹è¯•(1000è®­ç»ƒæ ·æœ¬+200éªŒè¯æ ·æœ¬)")
        print("  --epochs N                                       è®¾ç½®è®­ç»ƒè½®æ•°")
        print("  --batch_size N                                   è®¾ç½®æ‰¹æ¬¡å¤§å°")
        print("  --help, -h                                       æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯")
        return
    
    # æ•°æ®è·¯å¾„
    train_data_path = '../data/pretrain/pretrain_tensors_train.pkl'
    val_data_path = '../data/pretrain/pretrain_tensors_valid.pkl'
    vocab_path = '../data/pretrain/vocab_train.txt'
    
    # åˆ›å»ºæ•°æ®é›†
    print("\nåˆ›å»ºæ•°æ®é›†...")
    if args.use_small_dataset:
        print("ğŸš€ ä½¿ç”¨å°æ•°æ®é›†æ¨¡å¼ - å¿«é€Ÿæµ‹è¯•!")
        train_dataset = G2RetroPDesignAlignedDataset(train_data_path, vocab_path, max_samples=None, use_small_dataset=True)
        val_dataset = G2RetroPDesignAlignedDataset(val_data_path, vocab_path, max_samples=None, use_small_dataset=True)
    else:
        print("ä½¿ç”¨å®Œæ•´æ•°æ®é›†è¿›è¡Œè®­ç»ƒ")
        train_dataset = G2RetroPDesignAlignedDataset(train_data_path, vocab_path, max_samples=None)
        val_dataset = G2RetroPDesignAlignedDataset(val_data_path, vocab_path, max_samples=None)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset, 
        batch_size=args.batch_size,
        shuffle=True,
        collate_fn=lambda batch: g2retro_design_aligned_collate_fn(batch, train_dataset.vocab, train_dataset.avocab),
        num_workers=0
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        collate_fn=lambda batch: g2retro_design_aligned_collate_fn(batch, val_dataset.vocab, val_dataset.avocab),
        num_workers=0
    )
    
    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»ºæ¨¡å‹...")
    model = G2RetroPDesignAlignedModel(train_dataset.vocab, train_dataset.avocab, args)
    model = model.to(device)
    
    # æ‰“å°æ¨¡å‹å‚æ•°æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"\næ¨¡å‹å‚æ•°ç»Ÿè®¡:")
    print(f"å‚æ•°æ€»æ•°: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    
    print("\n" + "="*70)
    print("G2Retro-På®Œæ•´ç³»ç»Ÿæ ¸å¿ƒè¦ç´ éªŒè¯:")
    print("="*70)
    print("âœ“ å…±äº«ç¼–ç å™¨ï¼šGMPNï¼ˆæ¥è‡ªG2Retroï¼‰")
    print("âœ“ åŸºç¡€ä»»åŠ¡å¤´ï¼šG2Retroååº”ä¸­å¿ƒè¯†åˆ«æ¨¡å—")
    print("âœ“ åˆ†å­æ¢å¤å¤´ï¼šMolCLRä¸‰ç§å¢å¼ºç­–ç•¥")  
    print("âœ“ äº§ç‰©-åˆæˆå­å¯¹æ¯”å¤´ï¼šæ ¸å¿ƒåˆ›æ–°")
    print("âœ“ åŠ¨æ€æƒé‡è°ƒæ•´ï¼šåŸºäºRetroExplainer DAMTç®—æ³•")
    print("âœ“ åˆå§‹æƒé‡è®¾ç½®ï¼šL_base + L_recovery + 0.1Ã—L_contrastive")
    print("âœ“ æ•°æ®æµç¨‹ï¼šGp â†’ h_product, Gp_aug â†’ h_augmented, Gs â†’ h_synthons")
    print("âœ“ æ™ºèƒ½æƒé‡é€‚åº”ï¼šæ ¹æ®ä»»åŠ¡å­¦ä¹ è¿›åº¦åŠ¨æ€è°ƒæ•´")
    print("="*70)
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = G2RetroPDesignAlignedTrainer(model, train_loader, val_loader, args)
    
    # å¼€å§‹è®­ç»ƒ
    trainer.train()
    
    print("\n" + "="*80)
    print("è®­ç»ƒå®Œæˆï¼")
    print("æ¨¡å‹å·²æŒ‰ç…§è®¾è®¡æ–¹æ¡ˆå®Œå…¨å¯¹é½å®ç°")
    print("="*80)

if __name__ == "__main__":
    main() 